{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b58bb8",
   "metadata": {},
   "source": [
    "# Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f23302",
   "metadata": {},
   "source": [
    "Für die Klassifikation wirst du wieder das `digits`-Datenset nutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cad60",
   "metadata": {},
   "source": [
    "## Datenset laden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242559e",
   "metadata": {},
   "source": [
    "Diesen Teil kennst du schon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10839cb1",
   "metadata": {},
   "source": [
    "Für *Supervised Learning* wirst du die Konvention nutzen, dass die unabhängigen Daten immer `X` heißen, während du die abhängigen Daten `Y` nennst. Die Aufgabe ist also, `X` zu nutzen, um `Y` vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e62893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits[\"data\"]\n",
    "y = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81dff93",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb879ad",
   "metadata": {},
   "source": [
    "Zuerst probierst du das *Naive Bayer*-Verfahren zur Klassifikation aus. Im Gegensatz zum Clustering benötigst du hier einen Schritt mehr - das Modell muss zunächst *trainiert* werden. Dazu dient die Funktion `fit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6726ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6ef31",
   "metadata": {},
   "source": [
    "Wenn das Modell trainiert ist, kann es Vorhersagen durchführen. Du übergibst ihm dazu Daten und es sagt dir, welche Zahl sich dahinter verbirgt. Probier es aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0feb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pred = mnb.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d5c099",
   "metadata": {},
   "source": [
    "Um zu sehen, wie oft es richtig und falsch vorhergesagt hast, kannst du einfach die beiden Arrays miteinander vergleichen (weil es `numpy.array`s sind) und zählen, wie häufig `True` und `False` vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(mnb_pred == y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa01d5",
   "metadata": {},
   "source": [
    "10% Fehler, das sieht gar nicht schlecht aus! Das Verhältnis von richtig klassifizierten Daten zu allen nennt sich *Accuracy* und kann einfach berechnet werden. Achtung, es ist nicht immer ein besonders gut geeignetes Maß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "(u, c) = np.unique(mnb_pred == y, return_counts=True)\n",
    "c[1]/c.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fccae22",
   "metadata": {},
   "source": [
    "Andere Klassifikationsverfahren sind noch besser. *Naive Bayes* ist immer die *Baseline*, an der sich alles messen sollte - alle andere Verfahren müssten eigentlich besser sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e1a82",
   "metadata": {},
   "source": [
    "## Andere Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed18b3",
   "metadata": {},
   "source": [
    "Da `scikit-learn` ziemlich viele Verfahren hat, schreibst du dir dazu eine kleine Schleife."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for clf in [MultinomialNB(), SVC(random_state=42), SGDClassifier(random_state=42),\n",
    "            RandomForestClassifier(), GradientBoostingClassifier(random_state=42),\n",
    "            AdaBoostClassifier(random_state=42), DecisionTreeClassifier(random_state=42),\n",
    "            MLPClassifier(random_state=42), KNeighborsClassifier()]:\n",
    "    clf.fit(X, y)\n",
    "    clf_pred = clf.predict(X)\n",
    "    (u, c) = np.unique(clf_pred == y, return_counts=True)\n",
    "    print(clf, c[-1]/c.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464edb8c",
   "metadata": {},
   "source": [
    "Die Ergebnisse unterscheiden sich sehr deutlich - genau wie auch die Rechenzeiten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcffac",
   "metadata": {},
   "source": [
    "## Welches ist der richtige Algorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872967e",
   "metadata": {},
   "source": [
    "Wie du siehst, ist eine Klassifikation mit `scikit-learn` sehr einfach durchführbar. Doch welches ist nun der richtige Algorithmus? Das kannst du noch nicht entscheiden, weil du die Abstraktionsfähigkeit der Klassifikatoren noch nicht bewerten kannst. Außerdem ist die *Accuracy* auch nicht immer das am besten geeignete Maß, um die Leistungsfähigkeit zu beurteilen.\n",
    "\n",
    "Genaueres dazu erfährst du im nächsten Teil!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
