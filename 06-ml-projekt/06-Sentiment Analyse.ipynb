{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f transport-all-comments.csv.xz || wget  https://github.com/heiseacademy/ml-python/raw/main/06-ml-projekt/transport-all-comments.csv.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "posts = pd.read_csv(\"transport-all-comments.csv.xz\", parse_dates=[\"created_utc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = posts[posts[\"text\"].str.contains(\"tesla\")].copy()\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musk = posts[posts[\"text\"].str.contains(\"musk\")].copy()\n",
    "len(musk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU %s\" % torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU :-(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "# das Modell muss zum Tokenizer passen!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False # wir benötigen keine Embeddings\n",
    ")\n",
    "# hier evtl. model.cuda() einsetzen\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def calculate_sentiment(df):\n",
    "    # in scores kommen die Ergebnisse rein\n",
    "    scores = []\n",
    "    \n",
    "    # die Schleife nutzt 100er Batches\n",
    "    for i in tqdm(range((len(df)-1)//100 + 1)):\n",
    "        # wichtige interne Datenstrukturen\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        # damit iterierst du über 100 Datensätze im DataFrame\n",
    "        for t in df[i*100:(i+1)*100][\"text\"].map(str).values:\n",
    "            # die Texte tokenisieren\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                t,\n",
    "                                add_special_tokens = True,    # '[CLS]' und '[SEP]'\n",
    "                                max_length = 64,\n",
    "                                truncation = True,\n",
    "                                padding='max_length',\n",
    "                                return_attention_mask = True,  # Attention-Masks erzeugen\n",
    "                                return_tensors = 'pt',         # pytorch-Tensoren als Ergebnis\n",
    "                           )\n",
    "            # interne Strukturen befüllen\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        # Jetzt hast du die input_ids und attention_masks für den Batch bestimmt\n",
    "        # nun musst du sie noch in Tensoren wandeln\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)        \n",
    "\n",
    "        # Du willst das Modell nur auswerten, nicht trainieren, daher ist kein Gradient notwendig\n",
    "        with torch.no_grad():\n",
    "            # Auswertung durchführen (dieser Schritt dauert!)\n",
    "            res = model(input_ids.to(device), attention_mask=attention_masks.to(device))\n",
    "            # res[0] enthält die Ergebnisse, das .cpu().detach() ist für GPUs notwendig\n",
    "            for r in res[0].cpu().detach().numpy():\n",
    "                # du speicherst in Scores die softmax-Werte für alle Sentiment-Ergebnisse,\n",
    "                # also im Prinzip die Wahrhscheinlichkeit für Sentiment 1, 2, 3, 4 und 5\n",
    "                scores.append(list(softmax(r)))\n",
    "    \n",
    "    # jetzt überträgst du die Sentimentwerte en bloc in den DataFrame\n",
    "    df[\"s1\"] = df[\"s2\"] = df[\"s3\"] = df[\"s4\"] = df[\"s5\"] = None\n",
    "    df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]] = scores\n",
    "    \n",
    "    # das ist das \"wahrscheinlichste\" Sentiment\n",
    "    df[\"sentiment\"] = [np.argmax(s)+1 for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # und hier berechnest du den Erwartungswert\n",
    "    df[\"sentiment_avg\"] = [s[0] + 2*s[1] + 3*s[2] + 4*s[3] + 5*s[4] \n",
    "                                for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # die Varianz gibt die einen Eindruck über die Verlässlichkeit...\n",
    "    df[\"sentiment_var\"] = [(s[0] + 2*2*s[1] + 3*3*s[2] + 4*4*s[3] + 5*5*s[4]) - \n",
    "                               (s[0] + 2*s[1] + 3*s[2] + 4*s[3] + 5*s[4])**2\n",
    "                                  for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # ... genau wie die Standardabweichung\n",
    "    df[\"sentiment_dev\"] = np.sqrt(df[\"sentiment_var\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_sentiment(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_sentiment(musk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = tesla.set_index(\"created_utc\")[[\"sentiment\"]].resample(\"M\").mean()\n",
    "ms = musk.set_index(\"created_utc\")[[\"sentiment\"]].resample(\"M\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ts.merge(ms, how=\"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = cs[[\"sentiment_x\", \"sentiment_y\"]].rename(columns={\"sentiment_x\": \"sentiment_tesla\", \n",
    "                                                        \"sentiment_y\": \"sentiment_musk\"})\n",
    "cs.plot(figsize=(16,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_COLAB:\n",
    "    os.system(\"test -f tesla-stock.csv || wget  https://github.com/heiseacademy/ml-python/raw/main/06-ml-projekt/tesla-stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.nasdaq.com/market-activity/stocks/tsla/historical\n",
    "stock = pd.read_csv(\"tesla-stock.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.set_index(\"Date\")[\"Close/Last\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_scale = stock.set_index(\"Date\").resample(\"M\").mean()\n",
    "stock_scale[\"stock_value\"] = stock_scale[\"Close/Last\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = cs.merge(stock_scale, how=\"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css[[\"sentiment_tesla\", \"sentiment_musk\", \"stock_value\"]].plot(figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css[[\"sentiment_tesla\", \"sentiment_musk\", \"stock_value\"]].plot(figsize=(16, 9), logy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
