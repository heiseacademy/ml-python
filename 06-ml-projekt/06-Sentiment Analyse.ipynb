{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den vorherigen Notebooks hast du gesehen, dass Tesla ein wichtiges Thema ist, über da viel gesprochen wird. Allerdings hast du Grund zur Annahme, das die Diskussionen dort häufig kontrovers ablaufen.\n",
    "\n",
    "Um das zu bestimmen, kannst du eine Sentiment-Analyse der betroffenen Posts durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt liest du die Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f transport-all-comments.csv.xz || wget  https://github.com/heiseacademy/ml-python/raw/main/06-ml-projekt/transport-all-comments.csv.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "posts = pd.read_csv(\"transport-all-comments.csv.xz\", parse_dates=[\"created_utc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du könntest jetzt die Posts berücksichtigen, die zum Tesla-Topic gehören. Das ist aber nicht ganz eindeutig und evtl. reden die Nutzer dort auch über andere Themen. Am einfachsten ist es daher, wenn du einfach alle Posts berücksichtigst, die das Wort \"tesla\" enthalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = posts[posts[\"text\"].str.contains(\"tesla\")].copy()\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da sind ganz schön viele Posts. Das `.copy()` führt dazu, dass du mit unabhängigen Datensätzen arbeiten kannst. Das ist wichtig weil du bei diesen auch noch zusätzliche Felder hinzufügen wirst.\n",
    "\n",
    "Wo Tesla ist, kann Elon Musk nicht weit sein. Ist das damit verknüpft? Die Posts kannst du genauso bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musk = posts[posts[\"text\"].str.contains(\"musk\")].copy()\n",
    "len(musk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch nicht wenige!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun geht es an die Sentiment-Analyse. Du wirst dafür ein Modell von [Huggingface](https://huggingface.co/models) benutzen. Diese können Sentiments erkennen, benötigen dafür aber ordentlich Rechenzeit. Auf Grafikkarten geht es viel schneller!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU %s\" % torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU :-(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell `nlptown/bert-base-multilingual-uncased-sentiment` ist auf die Vorhersage von Sentiments spezialisiert und kann mit unterschiedlichen Sprachen arbeiten. Es liefer Werte von `1` bis `5` zurück, die den Sternchen bei Amazon-Reviews entsprechen.\n",
    "\n",
    "Jedes Modell benötigt einen dazu passenden `Tokenizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird das Modell geladen und auf die CPU verlagert (wenn du eine GPU hast, dann trage dort `model.cuda()` ein!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "# das Modell muss zum Tokenizer passen!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False # wir benötigen keine Embeddings\n",
    ")\n",
    "# hier evtl. model.cuda() einsetzen\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist die zentrale Funktion zum Berechnen der Sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def calculate_sentiment(df):\n",
    "    # in scores kommen die Ergebnisse rein\n",
    "    scores = []\n",
    "    \n",
    "    # die Schleife nutzt 100er Batches\n",
    "    for i in tqdm(range((len(df)-1)//100 + 1)):\n",
    "        # wichtige interne Datenstrukturen\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        # damit iterierst du über 100 Datensätze im DataFrame\n",
    "        for t in df[i*100:(i+1)*100][\"text\"].map(str).values:\n",
    "            # die Texte tokenisieren\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                                t,\n",
    "                                add_special_tokens = True,    # '[CLS]' und '[SEP]'\n",
    "                                max_length = 64,\n",
    "                                truncation = True,\n",
    "                                padding='max_length',\n",
    "                                return_attention_mask = True,  # Attention-Masks erzeugen\n",
    "                                return_tensors = 'pt',         # pytorch-Tensoren als Ergebnis\n",
    "                           )\n",
    "            # interne Strukturen befüllen\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        # Jetzt hast du die input_ids und attention_masks für den Batch bestimmt\n",
    "        # nun musst du sie noch in Tensoren wandeln\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)        \n",
    "\n",
    "        # Du willst das Modell nur auswerten, nicht trainieren, daher ist kein Gradient notwendig\n",
    "        with torch.no_grad():\n",
    "            # Auswertung durchführen (dieser Schritt dauert!)\n",
    "            res = model(input_ids.to(device), attention_mask=attention_masks.to(device))\n",
    "            # res[0] enthält die Ergebnisse, das .cpu().detach() ist für GPUs notwendig\n",
    "            for r in res[0].cpu().detach().numpy():\n",
    "                # du speicherst in Scores die softmax-Werte für alle Sentiment-Ergebnisse,\n",
    "                # also im Prinzip die Wahrhscheinlichkeit für Sentiment 1, 2, 3, 4 und 5\n",
    "                scores.append(list(softmax(r)))\n",
    "    \n",
    "    # jetzt überträgst du die Sentimentwerte en bloc in den DataFrame\n",
    "    df[\"s1\"] = df[\"s2\"] = df[\"s3\"] = df[\"s4\"] = df[\"s5\"] = None\n",
    "    df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]] = scores\n",
    "    \n",
    "    # das ist das \"wahrscheinlichste\" Sentiment\n",
    "    df[\"sentiment\"] = [np.argmax(s)+1 for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # und hier berechnest du den Erwartungswert\n",
    "    df[\"sentiment_avg\"] = [s[0] + 2*s[1] + 3*s[2] + 4*s[3] + 5*s[4] \n",
    "                                for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # die Varianz gibt die einen Eindruck über die Verlässlichkeit...\n",
    "    df[\"sentiment_var\"] = [(s[0] + 2*2*s[1] + 3*3*s[2] + 4*4*s[3] + 5*5*s[4]) - \n",
    "                               (s[0] + 2*s[1] + 3*s[2] + 4*s[3] + 5*s[4])**2\n",
    "                                  for s in df[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].values]\n",
    "    \n",
    "    # ... genau wie die Standardabweichung\n",
    "    df[\"sentiment_dev\"] = np.sqrt(df[\"sentiment_var\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments für Tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt ist die Berechnung natürlich sehr simpel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_sentiment(tesla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du siehst, hat das schon gut funktioniert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments für Musk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_sentiment(musk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier berechnest du nun die Mittelwerte der Sentiments pro Monat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = tesla.set_index(\"created_utc\")[[\"sentiment\"]].resample(\"M\").mean()\n",
    "ms = musk.set_index(\"created_utc\")[[\"sentiment\"]].resample(\"M\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und fügst die `DataFrame`s mit `.merge` zusammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ts.merge(ms, how=\"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das kannst du gut darstellen, nur die Namen der Felder musst du etwas umbenennen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = cs[[\"sentiment_x\", \"sentiment_y\"]].rename(columns={\"sentiment_x\": \"sentiment_tesla\", \n",
    "                                                        \"sentiment_y\": \"sentiment_musk\"})\n",
    "cs.plot(figsize=(16,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant! Besonders am Anfang sind die Fluktuationen bei `tesla` sehr hoch, später ist das Sentiment stabil bei etwa `1.5` (also sehr schlecht). Bei `musk` bleiben die Fluktuationen - wenig verwunderlich!\n",
    "\n",
    "Du interessierst dich nun dafür, ob die Community inhaltlich diskutiert oder ob das möglicherweise alles verkappte Investoren sind, die nur der Aktienkurs interessiert. Den Tesla-Aktienkurs kannst du dir von der NASDAQ herunterladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.nasdaq.com/market-activity/stocks/tsla/historical\n",
    "stock = pd.read_csv(\"tesla-stock.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.set_index(\"Date\")[\"Close/Last\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hätten wir doch alle in Tesla investiert - das ist ja fast wie Bitcoin zu den besten Zeiten! Um das besser vergleich zu können, skalierst du den Aktienkurs mit dem Faktor 100, dann passen die Größen zum Sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_scale = stock.set_index(\"Date\").resample(\"M\").mean()\n",
    "stock_scale[\"stock_value\"] = stock_scale[\"Close/Last\"] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann noch die `DataFrame`s verbinden und plotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = cs.merge(stock_scale, how=\"outer\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css[[\"sentiment_tesla\", \"sentiment_musk\", \"stock_value\"]].plot(figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine direkte Korrelation kannst du nicht erkennen. Für solche Daten eignet sich oft eine logarithmische Darstellung besser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css[[\"sentiment_tesla\", \"sentiment_musk\", \"stock_value\"]].plot(figsize=(16, 9), logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aber auch hier kann man keine direkte Korrelation erkennen. Offenbar geht es also beim Sentiment doch eher um Inhalte als um Aktienkurse!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
